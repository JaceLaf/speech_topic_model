To reach a final deliverable, perform the following steps.
First, you must derive a corpus of data in .gz.jsonl format. I got this from HathiTrust. My search parameters for this project were:
- Narrow 'Subject' field to 'speeches'
- Filter 'Publication year' to between 1870 and 1920
- Narrow 'Language' to 'English'
- Narrow 'Place of publication' to 'United States'

1. tokenize_corpus.py
   - Purpose: Tokenizes corpus by word
   - Input: corpus.gz.jsonl (derived from HathiTrust)
   - Output: tokenized.gz.jsonl
2. load_model.py
   - Purpose: Creates a set of files used for training and evaluating the model
   - Input: tokenized.gz.jsonl; use default arguments in file
   - Output: subdocs; dictionary
3. train_topic_model.py (run 5 times)
   - Purpose: Trains topic models based on number of subdocuments
   - Input: sudocs; dictionary; args.num_topics [10, 20, 30, 40, 50]
   - Output: model_[10, 20, 30, 40, 50]; topics_[10, 20, 30, 40, 50].json
4. apply_topic_model.py (run 5 times)
   - Purpose: Sums frequency of each topic across original corpus
   - Input: model_[10, 20, 30, 40, 50]; subdocs; dictionary
   - Output: counts_[10, 20, 30, 40, 50].json
5. inspect_topic_model.py (run 5 times)
   - Purpose: Visualizes the frequency of each topic in graphical form
   - Input: counts_[10, 20, 30, 40, 50].json; model_[10, 20, 30, 40, 50]
   - Output: counts_graph_[10, 20, 30, 40, 50].png
6. evaluate_model.py
   - Purpose: Evaluates the model by Perplexity and Coherence score
   - Input: subdocs; dictionary; model_[10, 20, 30, 40, 50]
   - Output: evaluation.json
7. generate_chart.py
   - Purpose: Visualizes the evaluation in chart format
   - Input: evaluation.json
   - Output: eval_chart.txt
